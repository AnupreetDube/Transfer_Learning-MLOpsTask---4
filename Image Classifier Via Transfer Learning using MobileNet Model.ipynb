{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************\n",
      "List of all the Layers in the model : \n",
      "\n",
      "0 : InputLayer False\n",
      "1 : ZeroPadding2D False\n",
      "2 : Conv2D False\n",
      "3 : BatchNormalization False\n",
      "4 : ReLU False\n",
      "5 : DepthwiseConv2D False\n",
      "6 : BatchNormalization False\n",
      "7 : ReLU False\n",
      "8 : Conv2D False\n",
      "9 : BatchNormalization False\n",
      "10 : ReLU False\n",
      "11 : ZeroPadding2D False\n",
      "12 : DepthwiseConv2D False\n",
      "13 : BatchNormalization False\n",
      "14 : ReLU False\n",
      "15 : Conv2D False\n",
      "16 : BatchNormalization False\n",
      "17 : ReLU False\n",
      "18 : DepthwiseConv2D False\n",
      "19 : BatchNormalization False\n",
      "20 : ReLU False\n",
      "21 : Conv2D False\n",
      "22 : BatchNormalization False\n",
      "23 : ReLU False\n",
      "24 : ZeroPadding2D False\n",
      "25 : DepthwiseConv2D False\n",
      "26 : BatchNormalization False\n",
      "27 : ReLU False\n",
      "28 : Conv2D False\n",
      "29 : BatchNormalization False\n",
      "30 : ReLU False\n",
      "31 : DepthwiseConv2D False\n",
      "32 : BatchNormalization False\n",
      "33 : ReLU False\n",
      "34 : Conv2D False\n",
      "35 : BatchNormalization False\n",
      "36 : ReLU False\n",
      "37 : ZeroPadding2D False\n",
      "38 : DepthwiseConv2D False\n",
      "39 : BatchNormalization False\n",
      "40 : ReLU False\n",
      "41 : Conv2D False\n",
      "42 : BatchNormalization False\n",
      "43 : ReLU False\n",
      "44 : DepthwiseConv2D False\n",
      "45 : BatchNormalization False\n",
      "46 : ReLU False\n",
      "47 : Conv2D False\n",
      "48 : BatchNormalization False\n",
      "49 : ReLU False\n",
      "50 : DepthwiseConv2D False\n",
      "51 : BatchNormalization False\n",
      "52 : ReLU False\n",
      "53 : Conv2D False\n",
      "54 : BatchNormalization False\n",
      "55 : ReLU False\n",
      "56 : DepthwiseConv2D False\n",
      "57 : BatchNormalization False\n",
      "58 : ReLU False\n",
      "59 : Conv2D False\n",
      "60 : BatchNormalization False\n",
      "61 : ReLU False\n",
      "62 : DepthwiseConv2D False\n",
      "63 : BatchNormalization False\n",
      "64 : ReLU False\n",
      "65 : Conv2D False\n",
      "66 : BatchNormalization False\n",
      "67 : ReLU False\n",
      "68 : DepthwiseConv2D False\n",
      "69 : BatchNormalization False\n",
      "70 : ReLU False\n",
      "71 : Conv2D False\n",
      "72 : BatchNormalization False\n",
      "73 : ReLU False\n",
      "74 : ZeroPadding2D False\n",
      "75 : DepthwiseConv2D False\n",
      "76 : BatchNormalization False\n",
      "77 : ReLU False\n",
      "78 : Conv2D False\n",
      "79 : BatchNormalization False\n",
      "80 : ReLU False\n",
      "81 : DepthwiseConv2D False\n",
      "82 : BatchNormalization False\n",
      "83 : ReLU False\n",
      "84 : Conv2D False\n",
      "85 : BatchNormalization False\n",
      "86 : ReLU False\n",
      "*****************************\n",
      "Model's Summary : \n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 5,854,916\n",
      "Trainable params: 2,626,052\n",
      "Non-trainable params: 3,228,864\n",
      "_________________________________________________________________\n",
      "None\n",
      "Found 62 images belonging to 4 classes.\n",
      "Found 3 images belonging to 4 classes.\n",
      "*****************************\n",
      "EPOCHS : \n",
      "WARNING:tensorflow:From E:\\SOFTWARES\\AnacondaInstall\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 20s 10s/step - loss: 5.3603 - accuracy: 0.1935 - val_loss: 17.0666 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 17.06662, saving model to face_recognition_model.h5\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 17s 8s/step - loss: 20.8526 - accuracy: 0.2097 - val_loss: 1.2772 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00002: val_loss improved from 17.06662 to 1.27723, saving model to face_recognition_model.h5\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 17s 9s/step - loss: 1.1037 - accuracy: 0.3871 - val_loss: 1.3243 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.27723\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 17s 9s/step - loss: 1.2517 - accuracy: 0.3226 - val_loss: 2.0765 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.27723\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 17s 9s/step - loss: 1.5753 - accuracy: 0.2581 - val_loss: 1.1734 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.27723 to 1.17341, saving model to face_recognition_model.h5\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 17s 9s/step - loss: 0.8782 - accuracy: 0.7258 - val_loss: 1.0750 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.17341 to 1.07496, saving model to face_recognition_model.h5\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 17s 8s/step - loss: 0.7698 - accuracy: 0.5323 - val_loss: 2.2148 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.07496\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 17s 9s/step - loss: 1.3381 - accuracy: 0.5323 - val_loss: 1.6164 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.07496\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 17s 9s/step - loss: 0.7517 - accuracy: 0.5968 - val_loss: 1.0256 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.07496 to 1.02560, saving model to face_recognition_model.h5\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 17s 9s/step - loss: 0.9179 - accuracy: 0.6452 - val_loss: 0.9027 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.02560 to 0.90269, saving model to face_recognition_model.h5\n"
     ]
    }
   ],
   "source": [
    "#Loading the MobileNet Model from Keras Library\n",
    "from keras.applications import MobileNet\n",
    "\n",
    "# MobileNet Model takes input images of 224x224 pixels\n",
    "row, col= 224, 224 \n",
    "\n",
    "# Re-loading the MobileNet model without the top  layers\n",
    "MobileNet = MobileNet(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape =( row, col, 3))\n",
    "\n",
    "#Freezing the layers. By default, they are trainable\n",
    "for layer in MobileNet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Printing the details of the models's layers \n",
    "print(\"*****************************\")\n",
    "print(\"List of all the Layers in the model : \\n\")\n",
    "for (n,layer) in enumerate(MobileNet.layers):\n",
    "    print(str(n) + \" : \"+ layer.__class__.__name__, layer.trainable)\n",
    "\n",
    "#This function is to create the Top Layer for the model which will be placed above the bottom layers\n",
    "def create_head(bottom_layers, num_classes):\n",
    "    top_layer = bottom_layers.output\n",
    "    top_layer = GlobalAveragePooling2D()(top_layer)\n",
    "    top_layer = Dense(1024,activation='relu')(top_layer)\n",
    "    top_layer = Dense(1024,activation='relu')(top_layer)\n",
    "    top_layer = Dense(512,activation='relu')(top_layer)\n",
    "    top_layer = Dense(num_classes,activation='softmax')(top_layer)\n",
    "    return top_layer\n",
    "\n",
    "#Placing the Top layer above the Bottom Layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "# Set our class number to 4\n",
    "num_classes = 4\n",
    "FC_Head = create_head(MobileNet, num_classes)\n",
    "model = Model(inputs = MobileNet.input, outputs = FC_Head)\n",
    "print(\"*****************************\")\n",
    "print(\"Model's Summary : \\n\")\n",
    "print(model.summary())\n",
    "\n",
    "### Loading our Dataset containing face Images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#**************************************\n",
    "train_data_dir = 'Dataset/train/'\n",
    "validation_data_dir = 'Dataset/validation/'\n",
    "#**************************************\n",
    "\n",
    "#AUGMENTATION \n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=45,\n",
    "      width_shift_range=0.3,\n",
    "      height_shift_range=0.3,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "# Specify Batch Size (typically on most mid tier systems we'll use 16-32)\n",
    "batch_size = 32\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(row,col),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(row, col),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "### Training out Model\n",
    "#Note we're using checkpointing and early stopping\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "             \n",
    "checkpoint = ModelCheckpoint(\"face_recognition_model.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 3, verbose = 1, restore_best_weights = True)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = RMSprop(lr = 0.001), metrics = ['accuracy'])\n",
    "\n",
    "# Enter the number of training and validation samples here\n",
    "#**************************************\n",
    "nb_train_samples = 62\n",
    "nb_validation_samples = 3\n",
    "#**************************************\n",
    "\n",
    "# We train 10 EPOCHS because out dataset is small\n",
    "epochs = 10\n",
    "batch_size = 30\n",
    "\n",
    "print(\"*****************************\")\n",
    "print(\"EPOCHS : \")\n",
    "history = model.fit_generator(train_generator, steps_per_epoch = nb_train_samples // batch_size, epochs = epochs, callbacks = callbacks, validation_data = validation_generator, validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Loading our model\n",
    "from keras.models import load_model\n",
    "classifier = load_model('face_recognition_model.h5')\n",
    "\n",
    "#VALIDATION\n",
    "#**************************************\n",
    "Default_Names = {\"[0]\": \"EdSheeran\", \"[1]\": \"Shawn_Mendez\",\"[2]\": \"ZyanMalik\"}\n",
    "Predicted_Names = {\"n0\": \"Ed_Sheeran \",  \"n1\": \"Shawn_Mendes\",\"n2\": \"Zyan_Malik\"}\n",
    "#**************************************\n",
    "\n",
    "#Configuring the Output : Image size and text/font\n",
    "def Output_Config(name, pred, im):\n",
    "    Name = Default_Names[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, Name, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "    \n",
    "# This function will load random images from a random folder of our Validation/testing Dataset\n",
    "def getRandomImage(path):\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Predicted_Class : \" + Predicted_Names[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,10):\n",
    "    #Calling The Random image loading function\n",
    "    input_im = getRandomImage(\"Dataset/validation/\") \n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "     #Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    #Calling the output displaying function\n",
    "    Output_Config(\"Model's_Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - Shawn_Mendez\n",
      "Class - ZyanMalik\n",
      "Class - Shawn_Mendez\n",
      "Class - Shawn_Mendez\n",
      "Class - EdSheeran \n",
      "Class - EdSheeran \n",
      "Class - Shawn_Mendez\n",
      "Class - EdSheeran \n",
      "Class - EdSheeran \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'.ipynb_checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e382a902fed8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0minput_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetRandomImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dataset/validation/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0minput_original\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_im\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0minput_original\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e382a902fed8>\u001b[0m in \u001b[0;36mgetRandomImage\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mrandom_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mpath_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfolders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_directory\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Class - \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmonkey_breeds_dict_n\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpath_class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mfile_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '.ipynb_checkpoints'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "classifier = load_model('face_recognition_model.h5')\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "monkey_breeds_dict = {\"[0]\": \"EdSheeran\", \n",
    "                      \"[1]\": \"Shawn_Mendez\",\n",
    "                      \"[2]\": \"ZyanMalik\",\n",
    "                     }\n",
    "\n",
    "monkey_breeds_dict_n = {\"n0\": \"EdSheeran \", \n",
    "                      \"n1\": \"Shawn_Mendez\",\n",
    "                      \"n2\": \"ZyanMalik\",\n",
    "                       }\n",
    "\n",
    "\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    monkey = monkey_breeds_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, monkey, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + monkey_breeds_dict_n[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,10):\n",
    "    input_im = getRandomImage(\"Dataset/validation/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
